# 교차검증
Fold out cross validation
K-fold cross validation

## 파이프 라인(Pipeline)
사이킷런의 Pipeline 클래스는 연속된 변환을 순차적으로 처리할 수 있는 기능을
제공하는 유용한 래퍼(Wrapper) 도구

## 교차 검증 (Cross Validation)
모델 성능 검증하기 위한 방법

### 홀드아웃 교차 검증(Holdout Cross Validation)
1) 전체 데이터를 학습데이터와 테스트 데이터로 나눔
2) 학습데이터는 모델 학습에, 테스트 데이터는 일반화 성능 추정을 위해 사용
3) 모델 선택을 통한 하이퍼 파리미터 튜닝
### K-겹 교차 검증(K-fold Cross )
#### 1) K겹 교차 검증에서는 중복없이 훈련 데이터를 K겹으로 랜덤하게 나눔  
  - K-1겹으로 모델을 훈련하고, 나머지 하나로 성능을 평가  
  - 즉, K번 반복하므로 K개의 서로 다른 모델을 얻을 수 있음  

#### 2) K겹 교차검증은 각각의 폴드에서 얻은 성능을 기반으로 평균 성능을 계산
 -  이 경우에는 홀드아웃 방법보다 데이터 분할에 덜 예민한 성능 평가 가능  
  - K겹 교차 검증은 중복을 허락하지 않기 때문에 모든 샘플이 검증에 딱 한번 사용됨  

#### 3) 추천하는 K 값은 10   
  - K가 크면 실행 시간이 길어짐, 따라서 큰 데이터는 작은 K 값을 선택해도 됨  
 
 ## 과적합 문제
 ### 과대적합
 모델이 학습 데이터에 너무 잘 맞지만 일반화(generalization)가 떨어지는 상황
#### 해결방법 : 
- 학습 데이터 추가 수집  
- 모델 제약 늘리기: 규제(regularization) 값 늘리기  
- 학습 데이터 잡음을 줄임 (오류 수정 및 이상치 제거)  
 ### 과소적합
 모델이 너무 단순하여 데이터에 내재된 구조를 학습하지 못하는 현상
#### 해결방법 : 
- 파라미터가 더 많은 모델 선택 
- 모델의 제약 줄이기: 규제(regularization) 값 줄이기  
- 과적합 이전까지 충분히 학습하기

### 과대적합/과소적합 판단하기
#### 학습 곡선(Learning Curve)의 편향과 분산 분석
샘플 데이터의 수에 따른 정확도 변화
#### 검증 곡선(Validation Curve)
##### 매개변수에 따른 정확도 변화
로지스틱 회귀의 매개변수 C (규제 강도와 반비례)

# 앙상블
여러 분류기를 하나로 연결하여 개별 분류기 보다 더 좋은 일반화 성능을 달성하는 것  
## 방법 
- 여러 분류 알고리즘 사용: 다수결 투표(Voting)
- 하나의 분류 알고리즘을 여러 번 사용: 배깅(Bagging), 부스팅(Boosting)
## 종류
- 다수결 투표(Majority Voting): 동일한 학습 데이터 사용
- 배깅(Bagging): 알고리즘 수행 마다 서로 다른 학습 데이터 추출하여 사용
    ex) Random Forest  
- 부스팅(Boosting): 샘플 뽑을 때 잘못 분류된 데이터 50%를 재학습에 사용 또는 가중치 사용

### 다수결 투표
- 동일한 학습데이터로 모델 구축
- 샘플 뽑을 때 중복 없음

### 배깅
- 알고리즘마다 별도의 학습 데이터를 추출(샘플링)하여 모델 구축에 사용
- 부트스트랩(Bootstrap) 사용  
    학습데이터 샘플링 시 복원 추출(중복)을 허용
#### 랜덤 포레스트
- 배깅의 일종
- 단일 분류 알고리즘(Decision Tree) 사용
- Forest 구축: 무작위로 예측변수 선택하여 모델 구축
- 결합 방식: 투표(분류), 평균화(예측)

### 부스팅
- 샘플 뽑을 때 잘못 분류된 데이터의 50%를 재 학습에 사용
- AdaBoost: 전체 학습데이터를 사용하고 잘못 분류된 데이터에 가중치 적용










